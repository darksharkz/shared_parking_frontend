%%% File-Information {{{
%%% Filename: thesis_main.tex
%%% Purpose: bachelor thesis
%%%
%%% Notes:
%%%
%%%
%%%
%%% }}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% main document {{{

\documentclass[
a4paper,     %% defines the paper size: a4paper (default), a5paper, letterpaper, ...
% twoside,     %% changes to a two-page-layout (alternatively: oneside)
% headsepline, %% add a horizontal line below the column title
% footsepline, %% add a horizontal line above the page footer
titlepage,   %% only the titlepage (using titlepage-environment) appears on the first page (alternatively: notitlepage)
% parskip,     %% insert an empty line between two paragraphs (alternatively: halfparskip, ...)
% leqno,       %% equation numbers left (instead of right)
% fleqn,       %% equation left-justified (instead of centered)
% tablecaptionabove, %% captions of tables are above the tables (alternatively: tablecaptionbelow)
14pt         %% set default font size to 12 point
]{scrartcl}  %% article, see KOMA documentation (scrguide.dvi)



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% packages
%%%

%%%
%%% encoding and language set
%%%

%%% fontenc, ae, aecompl: coding of characters in PDF documents
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}

%%%
%%% technical packages
%%%

%%% amsmath, amssymb, amstext: support for mathematics
\usepackage{amsmath,amssymb,amstext,amsthm}
\newtheoremstyle{mystyle}%                % Name
  {}%                                     % Space above
  {}%                                     % Space below
  {\itshape}%                                     % Body font
  {}%                                     % Indent amount
  {\bfseries}%                            % Theorem head font
  {.}%                                    % Punctuation after theorem head
  { }%                                    % Space after theorem head, ' ', or \newline
  {\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}%                                     % Theorem head spec (can be left empty, meaning `normal')

\theoremstyle{mystyle}
\newtheorem*{definition}{Definition}
\newtheorem*{satz}{Satz}
\newtheorem*{prot}{Protokoll}
\renewcommand*{\proofname}{Beweis}
%\let\oldproofname=\proofname
%\renewcommand*{\proofname}{\rm\bf{\oldproofname}}
%\renewenvironment{proof}{{\bfseries Proof}}{}


%%% psfrag: replace PostScript fonts
\usepackage{psfrag}

%%% listings: include programming code
%\usepackage{listings}

%%% units: technical units
%\usepackage{units}

%%%
%%% layout
%%%

%%% scrpage2: KOMA heading and footer
%%% Note: if you don't use this package, please remove 
%%%       \pagestyle{scrheadings} and corresponding settings
%%%       below too.
\usepackage[automark]{scrpage2}


%%%
%%% PDF
%%%

\usepackage{ifpdf}

%%% Should be LAST usepackage-call!
%%% For docu on that, see reference on package ``hyperref''
\ifpdf%   (definitions for using pdflatex instead of latex)

  %%% graphicx: support for graphics
  \usepackage[pdftex]{graphicx}

  \pdfcompresslevel=9

  %%% hyperref (hyperlinks in PDF): for more options or more detailed
  %%%          explanations, see the documentation of the hyperref-package
  \usepackage[%
    %%% general options
    pdftex=true,      %% sets up hyperref for use with the pdftex program
    %plainpages=false, %% set it to false, if pdflatex complains: ``destination with same identifier already exists''
    %
    %%% extension options
    backref,      %% adds a backlink text to the end of each item in the bibliography
    pagebackref=false, %% if true, creates backward references as a list of page numbers in the bibliography
    colorlinks=true,   %% turn on colored links (true is better for on-screen reading, false is better for printout versions)
    %
    %%% PDF-specific display options
    bookmarks=true,          %% if true, generate PDF bookmarks (requires two passes of pdflatex)
    bookmarksopen=false,     %% if true, show all PDF bookmarks expanded
    bookmarksnumbered=false, %% if true, add the section numbers to the bookmarks
    %pdfstartpage={1},        %% determines, on which page the PDF file is opened
    pdfpagemode=None         %% None, UseOutlines (=show bookmarks), UseThumbs (show thumbnails), FullScreen
  ]{hyperref}


  %%% provide all graphics (also) in this format, so you don't have
  %%% to add the file extensions to the \includegraphics-command
  %%% and/or you don't have to distinguish between generating
  %%% dvi/ps (through latex) and pdf (through pdflatex)
  \DeclareGraphicsExtensions{.pdf}

\else %else   (definitions for using latex instead of pdflatex)

  \usepackage[dvips]{graphicx}

  \DeclareGraphicsExtensions{.eps}

  \usepackage[%
    dvips,           %% sets up hyperref for use with the dvips driver
    colorlinks=false %% better for printout version; almost every hyperref-extension is eliminated by using dvips
  ]{hyperref}

\fi


%%% sets the PDF-Information options
%%% (see fields in Acrobat Reader: ``File -> Document properties -> Summary'')
%%% Note: this method is better than as options of the hyperref-package (options are expanded correctly)
\hypersetup{
  pdftitle={Design of a Shared Parking System with special attention to security aspects}, %%
  pdfauthor={Simon Englert}, %%
  pdfsubject={}, %%
  pdfcreator={Accomplished with LaTeX2e and pdfLaTeX with hyperref-package.}, %% 
  pdfproducer={}, %%
  pdfkeywords={} %%
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% user defined commands
%%%

%%% \mygraphics{}{}{}
%% usage:   \mygraphics{width}{filename_without_extension}{caption}
%% example: \mygraphics{0.7\textwidth}{rolling_grandma}{This is my grandmother on inlinescates}
%% requires: package graphicx
%% provides: including centered pictures/graphics with a boldfaced caption below
%% 
\newcommand{\mygraphics}[3]{
  \begin{center}
    \includegraphics[width=#1, keepaspectratio=true]{#2} \\
    \textbf{#3}
  \end{center}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% define the titlepage
%%%

% \subject{}   %% subject which appears above titlehead
% \titlehead{} %% special heading for the titlepage

%%% title
\title{Design of a Shared Parking System with special attention to security aspects}

%%% author(s)
\author{Simon Englert (2136190)}

%%% date
\date{WÃ¼rzburg, am \today{}}

% \publishers{}

% \thanks{} %% use it instead of footnotes (only on titlepage)

% \dedication{} %% generates a dedication-page after titlepage


%%% uncomment following lines, if you want to:
%%% reuse the maketitle-entries for hyperref-setup
%\newcommand\org@maketitle{}
%\let\org@maketitle\maketitle
%\def\maketitle{%
%  \hypersetup{
%    pdftitle={\@title},
%    pdfauthor={\@author}
%    pdfsubject={\@subject}
%  }%
%  \org@maketitle
%}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% set heading and footer
%%%

%%% scrheadings default: 
%%%      footer - middle: page number
\pagestyle{scrheadings}

%%% user specific
%%% usage:
%%% \position[heading/footer for the titlepage]{heading/footer for the rest of the document}

%%% heading - left
% \ihead[]{}

%%% heading - center
% \chead[]{}

%%% heading - right
% \ohead[]{}

%%% footer - left
% \ifoot[]{}

%%% footer - center
% \cfoot[]{}

%%% footer - right
% \ofoot[]{}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% begin document
%%%

\begin{document}

% \pagenumbering{roman} %% small roman page numbers

%%% include the title
% \thispagestyle{empty}  %% no header/footer (only) on this page
 \maketitle

%%% start a new page and display the table of contents
% \newpage
 \tableofcontents

%%% start a new page and display the list of figures
% \newpage
% \listoffigures

%%% start a new page and display the list of tables
% \newpage
% \listoftables

%%% display the main document on a new page 
 \newpage

% \pagenumbering{arabic} %% normal page numbers (include it, if roman was used above)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% begin main document
%%% structure: \section \subsection \subsubsection \paragraph \subparagraph
%%%

\section{Abstract}
As major cities are growing more and more, the parking situation in those cities is becoming more precarious than ever. Parking demand already exceeds the limited amount of parking spaces available, and thus people searching for a place to park generate a significant part of those cities traffic. This leads to frustration with drivers, more traffic jams, unnecessary use of petrol and further air pollution. The creation of new parking spaces is often either difficult or very expansive, which means existing parking spots have to be used more efficiently. Solutions realizing that idea to try and solve those problems are for the most part called intelligent parking systems. This thesis is focused on Shared Parking, a special kind of intelligent parking system, which opens the possibility of sharing a parking place between different people. This work features the design and implementation of such a system with special attention given to security aspects.

\section{Indrodution}

Parking in large cities is not a new problem. For decades, the search for a parking space has been something that annoys most people. Due to the ever faster growing cities in recent years, the resulting difficulties are only intensifying. The ensuing traffic for example already represents a significant part of the total traffic in city centres. According to studies around 30 percent of the daily city traffic comes from car park seekers.\cite{shoup2006cruising} In addition to the rising number of people in cities, the percentage of people who own a car continues to increase, which adds to the traffic problem. However, the traffic is not just frustrating for the drivers. The ensuing traffic jams and slow-moving traffic cause an increased amount of petrol to be burned and the air to become additionally polluted. Especially in these times, when air pollution and climate warming are becoming even more important due to Dieselgate and the capricious weather conditions, one should be looking for a solution.

The creation of new parking spaces is rarely an option. On one hand, this is often associated with high costs, on the other hand, there is usually no space for the construction of new parking spaces available in the cities. Instead, existing parking spaces must be used more effectively.

This can be done in many different ways. So-called intelligent parking systems increase the smartness of parking in different areas and therefore often lead to a more effective use of parking spaces. Intelligent parking systems are available in various forms and for most of them there are numerous scientific papers and completed projects. However, there are hardly any relevant developments for shared parking systems, which are by definition a type of intelligent parking system. A shared parking system is a trading platform on which private users can rent out and rent parking spaces. Sharing systems, such as car sharing, have become increasingly influential in recent years and are expected to continue to grow strongly. If an object is shared among different users, it is used more effectively. This applies to parking places and a shared parking system as well. Therefore, the main part of this work will be concerned with designing a shared parking system. Special attention is paid to security aspects by detailing how the system handles fraud.

First, an overview of the system is presented, in particular the system model, which depicts the different roles in a shared parking system. This is followed by functional and security requirements to be met by the design. In contrast to existing systems, the design of our system will try avoid complex hardware and manual intervention. Possible cases of fraud are described and it is noted that our system must recognize and prevent them, punish the scammers and compensate the injured party. The actual design is described in the next step. First all functional features and then the security features that determine how to deal with fraud are explained. Various modules are introduced to deal with fraud, for example enabling the rating of users or the reporting and verification of fraud. 

Subsequently, the design is evaluated on the basis of the requirements. We shall find, that the security requirements are met in most cases and that the error probability approaches 0 with increasing system size.

Once it has been shown that the design meets the requirements, an implementation, which is also part of this study, will be discussed in more detail. The design was implemented as a client-server model with Java web service running on a TomCat server and Android app for the end user.

Finally, future work will be proposed and a summary of the results will be drawn up.

\section{Related Work}
If one takes a look at existing work in the field of intelligent parking systems, he will encounter a huge chaos. There are countless scientific papers in the most diverse sub-areas of intelligent parking systems. In addition, there are numerous projects in which such systems have already been implemented. There are also some works that have set themselves the task of categorizing related work in this field. These usually serve well as a summary, but do not have uniform definitions and categorizations amongst each other. In the following we will therefore present an introduction to the topic based on these papers.

\subsection{Overview}

\subparagraph{Intelligent Parking Systems}
In general terms, Intelligent Parking Systems, also called Smart Parking Systems, are systems that try to solve the countless parking problems already mentioned while integrating 'advanced technologies and researches from various academic disciplines' \cite{idris2009car}. Thus the words intelligent or smart have different meanings depending on the time at which a system was developed \cite{fraifer2016investigation}. With further progress, especially in information technology, new opportunities are opening up and old implementations no longer seem to be 'advanced' or 'smart', but were at the time of development.

\subparagraph{Shared Parking}
Shared Parking Systems form a separate category of Intelligent Parking Systems, because they use the emerging 'shared technology' in connection with mobile devices, which are available to most people due to technological advances. Shared parking provides the framework for making purely private parking spaces available to the public by allowing them to be traded as a commodity. \cite{itdp2014shared} By sharing, parking spaces can be used more effectively and information can be distributed more easily, which reduces the aforementioned parking problems. It is taken advantage of the fact that most private parking spaces are only used by certain groups of motorists at particular times and thus remain unused for a large part of the time and that those parking times for the different groups often do not overlap.\cite{vtpi2015shared} A supermarket, for example, needs its parking spaces mainly during the day when the supermarket is opened, while a hotel needs the parking spaces at night for the overnight guests.\\

\subsection{Intelligent Parking Systems}

To give an overview we are introducing a categorization of those systems proposed by Susan Shaheen in Smart parking management field test: A bay area rapid transit (bart) district parking demonstration.\cite{shaheen2005smart} Shaheen divides intelligent parking systems into five categories.

\subparagraph{Guidance Information Systems}
Guidance Information Systems are the simplest type of intelligent parking systems. The aim of such systems is to point the car park seeker to the nearest available parking spaces. In many cities this is done by simple displays on the streets, which point to car parks and show the number of free parking spaces available in real time.

\subparagraph{Transit-Based Information Systems}
Transit-Base Information Systems are just like the previously mentioned GIS pure information systems. However, special importance is given in this case to draw attention to parking spaces and to direct to parking spaces that are linked directly to local public transport. In most cases such parking spaces are called 'Park+Ride' and allow free parking, for example. The main objective of these systems, in addition to reducing the traffic of those seeking parking, is to reduce any traffic in the city centres. The aim is to make public transport more attractive and useable in order to prevent air pollution and congestion in the cities themselves. 

\subparagraph{Smart Payment Systems}
With Smart Payment Systems operators try to minimize their maintenance costs. Setting up, emptying and repairing coin-operated machines at parking lots is often an expensive business. Operators of Smart Payment Systems therefore try to forgo using these machines. Instead, the customer pays, even contactless, with smartcards or via his own smartphone. This usually has advantages for both sides. For the customer the payment process is accelerated and he can avoid using cash and at the same time the operating costs are reduced.

\subparagraph{E-parking}
By E-parking, Shaheen referred to a special system that was under development in 2005 by a research consortium. The aim of the concept was to combine the various smart parking ideas. The system includes advanced guidance information systems, smart payments methods, reservation options and connectivity to other digital services. More generally, we consider e-parking to be systems that use all means of digitalisation to make the parking experience better and more effective for the user in all possible aspects.

\subparagraph{Automated Parking}
Automatic parking is a system in which the user simply drives the car to a general drop-off point and later picks it up from there. The system takes over the remaining transport route of the vehicle from the delivery point to the actual parking lot. Such systems also exist as manual versions, then called valet parking.

\subsection{Shared Parking}
Shaheen, like many others, pays little to or no attention to the topic of shared parking. However, according to the above definition, shared parking is a kind of intelligent parking system. Overall, there are hardly any scientific papers on this subject. There are already a few implementations of the idea, but these are either limited to certain cities or have hardly any users, which renders them useless. In addition, these systems are operated by private companies and therefore no information about the security within the system is publicly available.\\

Of the few scientific papers that exist, most are concerned with the allocation and pricing of parking spaces to potential tenants.

Shao et. al. and Yu et. al. propose in their works \cite{shao2016simple} and \cite{yu2018optimal} to use integer linear programming to maximize profits. Both studies show that their proposed strategies, in contrast to 'first-come-first-serve' or 'first-book-first-serve' strategies, lead to higher parking space utilisation and greater profits for operators of shared parking systems. Yu et. al. refer in their work only to the sharing of parking spaces of shopping malls at night. This also implies that, unlike our system, there is no fluctuation in the number of parking spaces over time which their system would not be able to handle.

Xu et. al. extend a classic matching mechanism (top trading cycles, ttc) for the parking spaces so that cash flow is allowed. They assumed that each participant owns at least one parking space and participates with this parking space in the ttc mechanism. For situations where participants are unable to rent out their own parking space or do not wish to rent another parking space, the mechanisms '(price-compatible) top trading cycles and deals (TTCD)' and 'price-compatible top trading cycles and chains (PC-TTCC)' are proposed as extensions to ttc. These allow, in addition to the already possible exchange of parking space in ttc, the flow and exchange of money within the system. These mechanisms allowed participants to save costs, but under certain circumstances negative platform's payoff would occur. \cite{xu2016private}

Xiao et. al. assign parking spaces to tenants in their work using a double auction mechanism. They present the "demander competition padding method (DC-PM)" auction mechanism based on a slot allocation rule and a transaction payment rule. Both demanders and bidders place their bids by specifying the parking price and time and the mechanism determines the allocation of the parking spaces. Since this mechanism can lead to distorted social welfare, a "modified demander competition padding method (MDC-PM)" auction mechanism is also proposed, which is however inferior to the first mechanism in terms of its usefulness for the participants. They show that both mechanism "can realize asymptotic efficiency as both demanders and suppliers approach infinity", but do not take the spatial requirements of the participants into account during the allocation process. \cite{xiao2018shared}

Zhang et. al. try to improve the competitiveness of shared parking lot providers compared to traditional parking lots. They use the Hotteling model to compare the product differentiation of the two parking systems and use equilibrium analyses to evaluate the parking prices. \cite{zhang2019pricing}

In all these papers, the utilisation of parking spaces or the social welfare in the system improves compared to the 'first-book-first-serve' mechanism, but the systems do not provide the user with the same level of transparency. In our shared parking system, users should be able to see exactly which parking spaces are available, choose from them and be sure to be able to use the selected parking space. This can only be implemented with 'first-book-first-serve' and the systems mentioned above are not able to provide this functionality.\\

In addition to parking space allocation through a matching mechanism, Kim et al. propose an infrastructure to help drivers find the optimal parking space. The infrastructure consists of Road Side Units (RSUs), which communicate with the cars of parking seekers and Fog servers, which monitor the availability of each parking lot. RSUs communicate directly with Fog servers in their vicinity and with each other through a Roadside Cloud. Users can now make a request while driving, which is then accepted by the RSUs. Through communication between the RSUs and with the Fog Servers, a matching problem with all car park seekers is established, solved and the allocation of parking spaces is sent back to the vehicles through the RSUs. \cite{Kim2015ASP}

The big problem for this system are the expensive implementation and maintenance costs which arise because a lot of hardware and sensors have to be installed. The operator has to provide the RSUs, the Fog Server, sensors for each parking spot and the Roadside Cloud and every participant requires appropriate channels of communication on his car to connect to the RSUs. Our system, on the other hand, will do without expensive hardware to reduce maintenance costs and enable anyone to participate.\\


A number of shared parking platforms have already been implemented, but in very few cases they have become established. Internationally, for example, justpark.com or mobypark.com offer this service, in Germany there are providers like parkplace.de and parklist.de. All these platforms offer private individuals the opportunity to offer their own parking spaces, but the supply is very limited.

At parkinglist.de, even in large German cities such as Munich, there is almost exclusively only information about public car parks or offers for monthly rented parking spaces from car park operators, but hardly any private offers.

At parkplace.de there is also only a small number of almost exclusively long-term parking spaces available. Moreover, this platform does not offer the possibility to automatically perform payments. Instead, payment-specific matters have to be agreed on with the landlord separately.

At justpark.com, which originates from England, there are almost exclusively public parking garages available in London, for example. However, many car parks also offer the possibility of making reservations.

At mobypark.com you can find some listings from private persons. However, Mobypark is not widespread and is only really represented in a few cities, such as Amsterdam and Paris.

However, none of the providers discloses information on how they can protect their systems and users from fraud and how they generally deal with fraud. This is presumably because, as Mobypark itself reports on its website, parking spaces are hardly rented for short periods of time like a few hours, but mainly for longer periods (several days to several months). In addition, most of the rented parking spaces are not publicly accessible and key cards or the like must be exchanged prior to and at the end of the rental process. These conditions already lead to a reduction of fraud possibilities. In our application, however, it should also be possible to rent freely accessible parking spaces, even for short periods of time. This creates new opportunities for fraud, which, unlike in the scientific papers mentioned above, we will address in this paper.

\subsection{Trust Systems}
In order to distinguish malicious and genuine users in our system, we will use a trust system. Since there is a large amount of scientific work and discussion in the area of trust systems, we will not develop any new methods ourselves and will instead fall back on already matured methods, adapt them to our system and thereby make them better fit our system.\\

Trust systems are used in many different forms for many different purposes. Therefore, we have sought to find methods developed for systems that are similar to ours. Finally, we will use a method from the area of "Trust Management and Reputation Systems in Mobile Participatory Sensing Applications". These are systems in which participants use smartphones or similar devices to send information that they received at various locations through the sensors of their devices to a backend server. We will later show how trust methods of such systems can be easily mapped to our trust system. Mousa et. al. wrote a survey on this topic in 2015, which gives a fundamental overview of this area of trust systems\cite{mousa2015trust}:\\

In all these systems, trust is used to assess the reputation of individual users. The calculated reputation is therefore a value for the trustworthiness of the participants and the quality of their contributions. Mousa classifies trust/reputations systems according to methodology, type of distribution and anonymity of participants. 

\subparagraph{Methodology} Either a Trusted Platform Module (TPM) or a reputations score can be used as a methodology for trust assessment. TPM are hardware chips that are installed in the devices of the participants and are therefore not suitable for our system. In the "Future Work" section, trust assessment using TPMs is discussed briefly. For our system, on however, the use of a reputation score, which is calculated directly from the behavior of the participant, is suitable. For the computation of this score the participants' latest activities and his old score are used.

\subparagraph{Type of distribution} The distribution in a trust system can be either central, collaborative or a combination of both. Since our trust score should be hidden from the participants and we possess a trust server, a centralized structure is suitable for us. In this case the trust server receives all information, i.e. the contributions and feedback of the participants, from which it is able to calculate the score of all participants. In collaborative systems, however, each participant computes a separate score for all other participants.

\subparagraph{Anonymity of participants} Finally, anonymous and non anonymous systems can be distinguished. In anonymous systems the anonymity of the participants is preserved. This is neither necessary nor useful in our system, as each participant must provide certain personal data to access our system. \\

In the section x.y.z.z reputation module we will use a trust system corresponding to the above established classification and modify it for our purposes.

The use of such a trust system however allows different attack types which are described in more detail in section x.y attacker model. In the security analysis we will finally show the robustness of our system against these attacks.

\section{System Model and Requirements}
Now that an overview of the topic has been provided, the next part will deal with a basic system model and the requirements that will be imposed on the design. The system model gives an overview of the different parties that exist in our shared parking model and their relationships with each other. The subsequent requirement analysis is divided into functional and security requirements. Special attention is paid to ensuring that the design is secure. For us security requirements do not only refer to standard security aspects such as encryption, user authentication and authentification, but in particular to the goal of designing our shared parking system in a way that it has the ability to handle fraud independently. The aim of those aspects is to prevent and punish individual users from scamming other users or the system. Various forms and examples of such fraud will be explained in more detail below. The design set up in the later part of the work will adhere to these requirements. We will now start of with a High-level Overview of the Shared Parking System.

\subsection{High-level Overview}
This section gives a high-level overview of the shared parking system to be designed and deals with the basic capabilities of the system. The shared parking system adheres to the definition supplied at the beginning. It offers a platform for an online marketplace where both private and business users can rent and lease parking spaces. End users have the possibility to install an app and participate in the marketplace via their smartphone. This also clarifies the basic capabilities of the system. Every user can offer his own parking spaces for specified periods of time on the platform for rent. Users can also view other users' listings, choose from them and rent those parking spaces. In this system, particular importance is attached to handling fraud. The subsequent requirements define the exact framework under which the design was developed. 

\subsection{System Model}
The following system model, which is depicted in figure xy, shows the various parties in our \textbf{shared parking system} $SPS$. On the one hand, there is exactly one \textbf{operator} or \textbf{service provider} $SP$. The $SP$ is responsible for the implementation of the design, operating the $SPS$ and making the systems services available to the users. The \textbf{users} $U$ are those who utilize the $SPS$. They can be divided into two roles, whereby a user can be part of both roles at different points in time. On the one hand, there are \textbf{landlords} who own a private \textbf{parking space} and want to rent it out over a certain period of time. On the other hand, there are \textbf{tenants} who are looking for a free parking space to rent for a specific time period.

This work covers fraud in $SPS$ in detail. In the \textbf{case of fraud}, users take on new roles. On the one hand there is the \textbf{adversary}, who is committing fraud, on the other hand there usually is an \textbf{injured party}, which has a disadvantaged caused by the fraud case.

We will later introduce important modules that deal with those fraud cases, in which users once again assume different roles.

The rating module deals with \textbf{ratings}. For each rating there is one user who issues, called the\textbf{ rating user} and one user who receives, called the \textbf{rated user}.

The reporting module deals with \textbf{reports}. One report belongs to one case of fraud. For each report there is one user who issues, called the \textbf{reporting user} and one user who receives, called the \textbf{reported user}.

The verification module verifies reports and the corresponding fraud case. Users who verify the reports are called \textbf{inspectors}.

In the reputation module, \textbf{contributions} from all \textbf{participants} of one fraud case are processed. The participant include the reporting user, reported user and the inspectors. A participants' contributions is the information he provide about the fraud case.

All roles are described in more depth in the detailed description of the modules.\\

To-Do: Figure of system model

\subsection{Functional Requirements}
The following will cover the main functional requirements in detail.
\subparagraph{Basic Hardware} Neither the operator nor the user should need any additional and expensive hardware. For getting the system to work the user just needs a off-the-shelf smartphone and the operator only needs to provide enough computational power to get the server running. There will be no sensors installed at the parking spots, no additional hardware used for confirming parking time or the likes of that.
\subparagraph{Intuitiveness} The implementation of the design should be intuitive to use. First time users should be able to book or rent a parking space within minutes. Tasks such as user authentication should not be to complex or time-consuming.
\subparagraph{Neutral Balance} The operator or the system has different costs and revenues. Thus, the operator can either make a profit or lose money. We impose the condition on the system that in the long run, the revenues at least cover or even exceed the costs. This means that there may be time spans in which the costs are greater than the revenues, but if you take a look at the system in the long term, the revenues must surpass the costs.
\subparagraph{Automatic Processing} Where possible, the system should be prevented from requiring manual intervention. All basic use cases should be able to run automatically by the system. The system may only request manual intervention in exceptional cases. On the one hand this should lead to a fast processing of all inquiries and on the other hand reduce the costs arising from manual work.
\subparagraph{More to come}hi\\

There are also areas that do not place any functional requirements. There are aspects to which no special significance is attached in this work. This includes, for example, all legal matters. On the one hand, this work is in the field of computer science and the author does not have the fundamental knowledge to evaluate and judge legal matters. On the other hand, the legal aspect of a shared parking system involves many and various legal factors, which would exceed the scope of this work. Nevertheless, attention was paid during the design to carry out as little legal interference as possible in order to avoid legal difficulties during the implementation.

\subsection{Attacker Model and Assumptions}

\subsubsection{Attacker Model and Classes of Fraud}
When we talk about fraud, we mean a user's ability to scam other users or the system using its normal functionality in order to gain a profit. In many cases, this has a negative impact on other users. There are numerous possibilities for fraud in the system, some of which are mentioned as follows. We will categorise all fraud cases into three different classes. From now on, we refer to a user who commits fraud as a scammer. Users who are affected by fraud in a negative way will be called injured or injured party. \\

\subparagraph{Class 1} The first class of fraud cases are the result of the general nature of a shared parking system. This class consists of fraud cases where a tenant has booked a parking space, but it is not available when he arrives. There could be different possibilities as to why the parking space is not available, examples of which are the following.
\begin{itemize}
\item Scammer parks in a car park, which another user has booked for this time.
\item Tenant overstays his booked parking time.
\item Landlord rents out a parking space, but remains on it himself.
\item Landlord offers the same parking space multiple times.
\item Landlord offers a parking space that does not exist.
\end{itemize}
As we will see later, Class 1 cases can be handled by our system without manual intervention. 

\subparagraph{Class 2} To deal with these class 1 cases, we will introduce various modules, such as a report module and a reputation module. While these modules will help to deal with Class 1 fraud, they create the opportunity for a new series of fraud cases. These new fraud cases, which we will group into Class 2, try to take advantage of the methods we have introduced to deal with Class 1 fraud. All well known attacks in this area are described in \cite{mousa2015trust} and are applied to our system as follows:
\begin{itemize}
\item \textbf{Corruption attack:} An attacker unintentionally or deliberately sends corrupted data and information. An example of a corruption attack is when a reporting user enters an incorrect license plate number for the reported user.
\item \textbf{On-off attack:} An attacker alternates between malicious and genuine behavior. This is particularly difficult to detect when the transition appears to occur randomly.
\item \textbf{Re-entry attack:} An attacker tries to white wash his trust value by rejoining the system with a new identity. In our system this corresponds to a new registration of an existing user.
\item \textbf{Collusion:} Several attackers act together and execute attacks collectively. Joint attacks have a greater impact on the system and are harder to detect than acting independently.
\item \textbf{Sybil attack:} This is an extension of the re-entry attack. An attacker creates multiple identities or accounts within the system and utilizes them in a collusion attack.
\item \textbf{Reputation lag exploitation:} The attacker uses the period between his first attack and the evaluation and corresponding downgrading of his trust value to launch a large number of attacks.
\item \textbf{GPS spoofing attacks:} The attacker tampers with the GPS location of his device.
\item \textbf{Unfair ratings:} The attacker does not rate another user according to his genuine opinion.
\item \textbf{Bad mouthing or negative discrimination attack:} The attacker raises false accusations or assigns a bad rating to a genuine user.
\item \textbf{Ballot stuffing or positive discrimination attack:} The attacker does not report misbehaviour or assigns a good rating to a malicious user.
%User tries to impose costs on to the system by doing false reports. Scammer pretends to be the injured party. Scammer accuses another user of fraud.
\end{itemize}
We shall see that Class 2 cases can also be dealt with mostly without manual intervention by using a robust reputation module. 

\subparagraph{Class 3} While the first two classes cover the main and most frequent cases of fraud, there are others. Class 3 cases differ from the other classes in that it will not be possible to solve them without manual intervention. These are exceptional cases that occur only in low frequency. Examples are given below.
\begin{itemize}
\item Landlord rents out parking spaces that they do not own themselves.
\item Tenant cancels booking of parking space without paying.
\end{itemize}
For this class of fraud cases, we will also show methods of dealing with them.\\

Most of these attacks can only be performed by registered users. In contrast, however, there is a case of fraud, which can also be carried out by persons outside the system. A parking offender who occupies a booked, private parking space does not necessarily have to be registered in the system. Dealing with this problem is not the main focus of this work, but a suggestion on how to deal with it when realizing the system will be provided later on.

\subsection{Assumptions}
The following are some assumptions that apply in our system.\\

\subparagraph{Sufficient parking spaces} We assume that there are always enough parking spaces available for compensation. If the system has low occupancy levels, a suitable free parking space can always be found. If this is not the case, there will always be landlords  who offer their parking spaces for a particularly expensive and overpriced costs. These places will still be vacant even in situations where almost all capacities are occupied. These are parking spaces that are still available for use as compensation for injured parties, even when there is a high level of occupancy. 

\subparagraph{Majority assumption} We assume that the majority of users in our system are acting according to the rules, meaning that there are always a maximum of 50 percent adversaries. One reason for this is that the majority of people are genuine, especially when they know that offenses are being punished hard. We also offer an opportunity to report inadvertent misdemeanors by yourself, in order to prevent major penalties. This prevents inadvertent misdemeanors by genuine users.\\

\subsection{Security Requirements}
The following will cover the main security requirements in detail. On the one hand, requirements are made on information technology security and on the other hand, requirements are mode on how to deal with fraud in the shared parking system. \\

The system must be able to handle all these cases of fraud mentioned in the attacker model above successfully. In the following we will define what we mean by 'successful handling'. We therefore set requirements that must be met for the various cases of fraud.
\subparagraph{Fraud Prevention} The design of the system should be such that fraud is fundamentally prevented. If this is not possible in all cases, it should be ensured that it is not worth the effort for the scammer or that scammers are quickly discovered. This is where the second point comes into play.
\subparagraph{Fraud Detection} The system should be able to detect fraud. This includes, on the one hand, the simple recognition of fraud and, on the other hand, the ability to correctly identify the scammer. The later is particularly important for the next point.
\subparagraph{Fraud Punishment} The design should be such that a scammer can be punished by the system. After a scammer is detected, the system should always be able to penalize him. Punishment can also support the first requirement by acting as a deterrent for fraud.
\subparagraph{Fraud Compensation} Finally, the system should be able to compensate an injured party. If injured are compensated, there is no need for genuine users to worry about fraud and thus enhances the attractiveness of the system.\\

There are also areas that do not place any special requirements on security. Even without a shared parking system, attacks on the private parking infrastructure are possible. One person can for example park their car in another person's private car park. The injured party has two options, both of which can have strong disadvantages for him. He could call the towing service, hope that the scammer has not left by its arriving time or he will have to bear the expensive towing fees himself. The other option is to do nothing and look for a new parking space for yourself. Such problems, which are already present, do not need to be solved. However, it can be seen as a added bonus to prevent such problems with good design choices for the shared parking system.


\section{Design}
With the requirements being defined, the next part is devoted to the actual design. As with the requirements, we will first have a look at the functional features before dealing with fraud.

\subsection{Functional features}
The functional features will be presented as use cases.
\subparagraph{User registration} The registration process is rather simple. A user registers by entering his e-mail address, his first and last name and a password. After confirming the data, a mail is sent to the specified address, in which the user must verify whether it actually is his address.

From this point on he can log into the system at any time using his mail address and password.

\subparagraph{Balance system} Each user has a credit balance that can be charged and paid out using standard payment options. Various events, such as renting or hiring out a parking space, lead to an increase or decrease to the credit balance. The precise calculation of the credit is defined below for the individual events. If a user's balance is negative, they will no longer be able to use the system. His credit must be recharged before his next action.

\subparagraph{Parking Space management} Before you can rent a parking space, you have to register it in the system. To do this, enter the address and select the exact location on a map so that the coordinates (latitude and longitude) of the car park can be stored in the system. In addition to registration, these parking spaces can also be removed.

\subparagraph{Renting out a parking space} If a user wants to rent out a parking space, he inserts an offer. He selects one of his parking spaces, specifies the time at which the parking space is available and the price that the rental will cost per hour.

\subparagraph{Renting a parking space} If a user wants to rent a parking space, first a map is presented. There his location can be displayed or he can search for a city/address to be centred. All currently available parking spaces are displayed on this map. In addition to the location, the user can specify the time at which he wishes to book the parking space. If he does, only parking spaces that are available for the entire time period are displayed.

\subparagraph{More to come}
  
\subsection{Security features}
In order to prevent fraud different modules are introduced. There is a rating module, reporting module and a verification module, all of which are explained below. These modules work together and provide information for a reputation module that assesses the trustworthiness of each user. At the end of this section an example is given on how the design utilizes those systems to handle fraud.

\subsubsection{Rating Module} The design of the shared parking system includes an rating module, allowing users to rate each other. After each rental agreement has been concluded, both tenants and landlords have the opportunity to give the other party a rating. The rating consists on the one hand of a points/star rating between 1 and 5, and on the other hand of a rating text. The user should share his experiences made with the other party and evaluate how satisfied the agreement went for him. The ratings each user received are displayed on his user page and in all of his offers. The rating system is designed to help eliminate scammers and encourage users to be as friendly and courteous as possible.

\subsubsection{Reporting Module} The next important component is the reporting module. Whenever a user detects a rule violation by another user, he has the possibility to report it. A distinction is made between the reporting user, the reported user and the inspectors, who will be explained in the section 'Verification Module' later.

Firstly, there is the possibility of reporting a violation that occurs during a rental contract. On the overview page of the contract, you can choose from various reporting reasons, all of which refer to this contract. If the user finds a suitable violation from the list, he selects it and the system can respond to it without manual intervention. For example, tenants always have the option "The rented parking space is occupied by another vehicle", in which the license plate of the car, which occupies the parking space, is also provided. In a similar way, there is the option "Tenant has overrun parking time". for landlords. For all reasons that are not explicitly mentioned, meaning that the system cannot resolve them automatically, there is a general reporting function that requires manual intervention from the provider.

If the system receives a report, it can be sure that it is always a case of fraud. Either the user reports a real fraud case, which in this case has to be fraud class 1, or it is a false report from the user, which he expects to benefit from. This would again be a case of fraud, which can be classified in fraud class 2. The system must therefore first check the truth of the report. The verification module exists for this purpose and is explained below. After the verification module has identified who the scammer is, the necessary steps for punishment can be taken. The section 'Sanctioning and Compensation' explains in detail how exactly the system acts to compensate or punish users.

\subsubsection{Verification Module} Another important security tool is the verification module. It allows the system to check who has really committed a rule violation. If a rule violation situation occurs and another user cannot occupy his legally entitled parking space, he will report it to the system. Since the report may also be false, the system must first verify who the real offender is: the reported user or the reporting user. For this purpose, other users are called upon to head to this place and to make a contribution to this case. Those users will then be called inspectors. The truth of the report can be verified by comparing the contributions of the reported user, the reporting user and the inspectors. The inspectors will receive a bonus on their balance for their service.

The module works in several steps. After a report is received, potential inspectors are selected and requested. They confirm whether they will verify the event or not. Afterwards, they verify the event and the system evaluates the contributions. \\

Since the location of the inspectors must be taken into account when selecting them, users have the option of deciding whether they want to participate in the verification system or not. There are two ways for all participating users to provide the system with location information. 
\begin{itemize}
\item The user allows the app to retrieve GPS data from the mobile device. The GPS data is only collected if a report needs to be verified. Directly after viewing the data, it is calculated whether the user is in the area, and the GPS data is deleted again.
\item The user selects an area on a map in which he generally wants to verify reports. GPS data is not necessary.
\end{itemize}

A list of all users that are eligible for verification is created. This means only users who have agreed to participate in the verification system and who are either in the vicinity of the location of the event themselves or whose verifying area contains the location of the event are chosen. This list will now be sorted in a way that the users who are most suitable are at the top and users who are less suitable are at the bottom. Suitability is determined using a 'connection' score, which is calculated for all available inspector. This score indicates the independence between the inspector and the reporting and the reported user. A low score is a sign of great independence. 'connection' is a score, which represents the number of common events between the inspector and the reporting user plus the number of common events between the inspector and the reported user in a certain period of time (e.g. the last six months). The following events increment the score between user 1 and 2 by a single point.
\begin{itemize}
\item User 1 books a parking space from user 2.
\item User 1 reports user 2.
\item User 1 verifies a report from user 2.
\end{itemize}

Next, the users from the list are asked whether they are able and willing to verify this event. This request is not sent to all users at the same time. Based on the reputations score (see below) it is determined how many inspectors n are needed to solve the case and requests are sent to the first n*3 inspectors of the list.\\

The selected users will receive a notification on their smartphone indicating the location of the event for review. They then confirm or reject whether they are able and willing to perform the verification within the next 30 minutes. If a user refuses or does not respond within 15 minutes, he will be removed from the list and the next user not yet contacted will receive a request. After n users have accepted the request, all other requests are revoked.\\

As soon as a user has accepted the request, he will receive exact information about the parking space. He then moves to the inspection point and states whether this parking space exists and which car is parked on it according to the license plate.\\

In the last step the contributions must be evaluated. This is done using the reputation system described below. For this purpose, the reputation of both parties to the conflict is assessed. As seen down below, not the trust values of the two parties are compared, but the trust of the contributions by those parties, in which both the trust value and other parameters have an influence. These other parameters include, for example, the inspectors' contributions and the ratings the two parties have received. \\

The verification module returns the user whose contribution possesses the lower trust value as the scammer. \\

In addition to the above, the verification module asks the reported user for feedback on this case. The reported user can either confirm or contradict the report of the reporting user. This is intended as a means of self-reporting by the reported user, which can reduce his punishment and does not negatively affect his reputation score. This is a good way for a genuine user to admit inadvertent misconduct. If it does, no more inspectors need to be requested and the verification module returns the reported user as the scammer. However, even if the reported user admits the fraud with his contribution, the case is passed to the reputation module to update the reputation scores of the participating users.

\subsubsection{Reputation Module} The last part of the security features is the reputation module. It stores a hidden reputation score $R_u$ for each user $u$, which is updated using the other security modules. The value indicates the trustworthiness of a user. It is needed to decide who is right in the event of a conflict. Based on this reputation score, a separate trust value $Trust(C)$ is determined for each contribution $C$ taking other parameters into account. In all cases where the contributions of the reporting and the reported user do not match, this value is used to make a decision. \\

Our reputation module is based on the "dynamic trusted set based reputation system" (DTSRS) developed by Mousa et. al. in \cite{mousa2017reputation}. It utilizes state-of-the-art trust systems presented in \cite{mousa2015trust} and offers better evaluation results than those. DTSRS was created for use in Mobile Participatory Sensing Applications, but is also suitable for our purposes. In the following we will explain the system, our changes to it and the mapping of our parameters to those of the DTSRS. \\

The reputation module uses a trust score to evaluate participants and their contributions. The trust of a contribution $Trust(C)$ is the probability that contribution $C$ is correct. The reputation score $R_u$ of a user $u$ is the synthesized probability that his contribution are and will be correct. With our shared parking system, every user can be a participant of any case, but the number changes from time to time. After all, the participants in each case are the reported user, the reporting user and all inspectors. Each participant of a case submits exactly one contribution for this case. The contributions are therefore the report by the reporting user, the confirmation or denial by the reported user and the contributions from the inspectors.\\

After every report received by the system, $R_p$ of all participants $p$ involved in the report is updated. In addition, the trust of the contributions of the reported user and the reporting user is evaluated. The trust is updated in these five steps:

\subparagraph{Contribution Evaluation}In the first step, the contributions $C$ are evaluated and a contribution evaluation value $\theta_C $ is calculated. In our case, the contributions are the report by the reporting user, the confirmation or denial by the reported user and the contributions from the inspectors. In the original DTSRS, the values of the contributions are within a certain range. For our module we assume the special case that each of these contributions has exactly one of two values: (0) the contribution is consistent with the contribution of the reporting user or (1) the contribution is not consistent with the contribution of the reporting user. The two values occupy exactly the margins of the original range. This allows us to continue calculating in exactly the same way as the original.

With the help of the mean of the contributions of the trusted set the module forms a ground truth and compares all contributions to it. With the help of an exponential distribution, a score between 0.37 and 1 is assigned, which corresponds to the contribution evaluation value $\theta_C $ of the contribution $C$.\\

\textit{Hier fehlen Formeln.}

\subparagraph{Feedback Processing}In this step, the feedback each participating user received is taken into account. The module calculates a aggregated feedback score $\alpha_p$ for each participating user $p$. In DTSRS, the user can receive feedback for each contribution. There, feedback refers to exactly one contribution and is then discarded. In our system, users receive feedback through the rating module. Thus, received ratings originate not only from participant, but from all users of the shared parking system. In order to avoid using a rating more than once in the calculation of a user's reputation score, \textit{feedback processing} utilizes exactly those ratings that have been entered since the user's reputation score was last updated. For the calculations, the ratings $F_r(p)$ (1 to 5 stars) of a participant $p$ given by rating user $r$ are normalized to the range [0,1]. Only ratings of users $r$ whose reputation score is greater than that of the rated participant $p$ are used ($R_r>R_p$). The individual ratings are weighted according to the reputation score of the rating user and the average is calculated, which also falls within the range [0,1]. The following equations describe the calculation, where $F$ is the number of rating users for each participant and $FH$ the number of rating users whose reputation score is higher than the reputation score of the rated user.
\begin{equation}
  F_{r,Eval}(p)=F_r(p)*R_q\; \forall r \in 1,2,...F, where\; R_r>R_p 
\end{equation}
\begin{equation}
  \alpha_p = \frac{\sum_{r=1}^{r=FH}F_{r,Eval}(p)}{FH}
\end{equation}

\subparagraph{A Temporal Proximity Factor} In DTSRS, the proximity factor measures the distance between the participant and the sensing area, as a larger distance is more likely to result in inaccurate measurements. In our shared parking system, the distance has no influence on the measurements, as anyone making a contribution must be at the location of the event. Instead, however, the temporal distance $\beta_p$ has an effect on the measurements, because the more time passes, the greater the probability that the situation at the location of the event will change, which results in inaccurate measurements. For this reason, we are dealing with a temporal proximity factor $\sigma_p$ in the range [0,1], which is calculated using an inverse Gompertz function from the temporal distance. For the reported and reporting user the temporal distance is 0 and the proximity factor is therefore maximum at 1. For every other participant $\beta_p$ describes the distance between the report and the participant's contribution in minutes.
\begin{equation}
  \sigma_p = 1 - a * e^{-be^{-c\beta_p}}
\end{equation}

\subparagraph{Trust Mapping} The trust of a contribution $Trust(C)$ is calculated exactly as with DTSRS. We take a weighting $\sum_{i_1}^{4} W_i = 1$, the three already calculated values contribution evaluation $\theta_p$, aggregated feedback $\alpha_p$ and the temporal proximity factor $\sigma_p$ and as a fourth value the reputation score $R_p$ of the participant $p$ and calculate the weighted average of these four values:
\begin{equation}
  Trust(C) = W_1 * \theta_p +W_2 *  \alpha_p +W_3 *  \sigma_p +W_4 *  R_p
\end{equation}
The reputation score of a new participant is first set to 0, meaning he or she must first earn the trust of the system.

\subparagraph{Reputation Update} When updating the reputations value of a participant $p$, DTSRS only uses the contribution evaluation $\theta_p$ and not the complete trust $Trust(C)$ of his contribution. The reason for this is that the proximity factor $\sigma_p$ cannot be influenced by the user and does not depend on the genuineness of the user. This value is also not included in the calculation in our module, as users further away from the location of the event take more time to reach it, regardless of whether they are malicious or genuine.

The new reputation value $R\prime\prime$, as we can see in a moment, will be calculated on the basis of the old reputation value $R_p$ anyway. If we would use $Trust(C)$ for the calculation, $R_p$ would therefore have an impact two times. Mousa et. al. also argue that with the omission of $R_p$ recent behaviour has a direct influence on the reputation score.

However, they do not provide any reason why agregated feedback $\alpha_p$ should not be included in the reputation update. Since the feedback in our system is independent of the individual contributions, but clearly provides a indication about the trustworthiness of a user, we will include it.\\

We update the reputation value consecutively with the contributions evaluation $\theta_p$  and the aggregated feedback $\alpha_p$. For both values there is a threshold $\tau_\theta$ and $\tau_\alpha$. If the previously calculated $\theta_p$ or $\alpha_p$ of a participant $p$ is higher than $\tau_\theta$ or $\tau_\alpha$, the reputation value is increased by $e_{r,\theta}$ or $e_{r,\alpha}$. If it is lower, the reputation value is decreased by $e_{p,\theta}$ or $e_{p,\alpha}$. $e_{p,\theta}>e_{r,\theta}$ and $e_{p,\alpha}>e_{r,\alpha}$ applies to punish attackers more severely. The update is described by the following equations: 
\begin{equation}
  R\prime_p = \begin{cases} R_p + e_{r,\theta}\quad if\; \theta_p>=\tau_\theta \\ R_p - e_{p,\theta}\quad if\; \theta_p<\tau_\theta \end{cases}
\end{equation}
\begin{equation}
  R\prime\prime_p = \begin{cases} R\prime + e_{r,\alpha}\quad if\; \alpha>=\tau_\alpha \\ R\prime - e_{p,\alpha}\quad if\; \alpha<\tau_\alpha \end{cases}
\end{equation}

If the value is above 1 or below 0 after the update, it is reset to the corresponding value (1 or 0).

\subsubsection{Sanctioning and Compensation} With these basic systems it is now possible for the system to punish scammers and compensate the injured parties. 

After a report has been received, the reporting user will first be provided with a new parking space, regardless of whether it later turns out that he was in fact the fraudster. For this purpose, the system selects the nearest parking space available for the entire duration of the reservation of the original parking space. The system now books this parking space for the reporting user, takes over the costs, and sends the information about it to his smartphone. The System however, will not pay the price which is officially offered for the replacement parking space, but will instead pay the average price of parking spaces in the area. This is calculated as the average price of all bookings of the last x months in a maximum distance of y kilometers. On registration, all users agree to make their parking space available as a replacement parking space for the average parking fee, if required. The reporting user can now use the replacement parking space and the owner of the replacement parking space will be fairly remunerated.

After a replacement parking space has been provided, the already explained verification and reputation modules are used to determine who the scammer is.

After the real offender is identified, he will be punished. The punishment of fraudsters is primarily enforced by a fine. The penalty will be deducted from his credit balance. This penalty will also be used to cover the costs of the fraud. Costs arise on the one hand when compensating the injured party and on the other hand when paying the inspectors. The penalty is calculated from the sum of the inspectors' credit bonuses and the remuneration of the landlord of the replacement car park. Thus there are no costs for the system when the offender is successfully identified.

\subsubsection{Example}
Figure \ref{img:example-grafik} on page \pageref{img:example-grafik} shows fraud within the system and how to deal with it. The procedure is explained in more detail below.\\

User 1 has booked a parking space in advance that belongs to user 2. He's already paid him. However, when he arrives to occupy the car space, he realizes that another user (user 3) is already blocking the parking place. He then uses the reporting system to report user 3 with his license plate. The system receives the message and then assigns other independent users with the task of checking the message. In the meantime, user 1 will be provided with a new parking space (parking space of user 4). He can use it free of charge for parking the same duration as his originally booked spot. After verifying the violation made by user 3, the system now collects the fine from him and pays user 4 for his parking space and the other users for verifying the report.\\

\begin{figure}
	\centering
	\includegraphics[width=13cm,height=11cm]{example_grafik.pdf}
	\caption{A possible example for the handling of rule violations}
	\label{img:example-grafik}
\end{figure}
 
Of course, it is also conceivable that user 3 has not occupied the parking space at all, but user 1 still reports him. In this case, the verifiers will report that the parking space is actually free. Now the system penalizes user 1 with a sum that covers the costs for the newly allocated parking space (of user 4) and the costs for the verifying users.\\

Another possibility is that user 3 has actually occupied the parking lot but has already left until the users arrive for verification. In this case, like above, the system would identify user 1 as the scammer, although user 3 violated the rules. It also imposes the fine on User 1. He now has the opportunity to challenge the fine. If he does, the confidence score comes into play. If both users are new users or neither of them has a particularly bad or good score, no fair decision can really be made and the costs incurred are borne by the system. In all other cases, when one user is clearly more trustworthy than another, the system decides in favor of the more trustworthy user.


\section{Security Analysis}
In the following, the design of the system is evaluated using the security features set up in the requirement analysis. We look at each point individually. But first we will note a few premise that we believe apply to our system. They will help us perform the security analysis.

Without established data and numbers on fraud in our system, we cannot work with probabilities or the like to show that our design meets the specified requirements. As far as possible, we will therefore work without such data. In places where this is no longer sufficient, we will show that the error probability of our methods approaches 0 with increasing size of the system.

\subsection{Fraud Detection}
Fraud detection includes the simple recognition of fraud as well as the ability to correctly identify the scammer.  \\

\subparagraph{Fraud recognition} Fraud recognition is exclusively achieved by the report system. As soon as a user detects a rule violation, he can report it and the system is informed. It is sufficient to recognize fraud by which another party would be harmed, because this would not be any different without the Shared Parking System. A parking offence only causes problems if another user, who is authorized to park, wants to park on it and with our system the other user now has the ability to report it. Thus, parking spaces with a shared parking system always provide a better possibility for fraud detection than without it. \\

\subparagraph{Scammer identification}The ability to correctly identify the scammer is provided by the verification and reputation module. \\

First, we show that our reputation module can generally distinguish between malicious and genuine users, while also defending itself against the attacks from class 2.

Our module is based on the DTSRS from \cite{mousa2017reputation}, in which Mousa et. al experimentally evaluated their system using different simulations and obtained the following results. They showed that their system "accurately assesses the quality of participants' contributions" and "clearly identifies adversaries even if the number of colluding adversaries reaches 60\% of the total number of participants" and furthermore defends itself against corruption, On-Off and collusion attacks. \\

Since we only map our system parameters to the parameters of Participatory Sensing in our module, we can adopt the evalutation and the resulting properties of DTSRS. In our assumptions we also expect to reach a maximum attacker percentage of 50\% in our system and thus remain below the 60\% with which DTSRS can still successfully deal with. Our module can either fend off attacks on a reputation system presented in the attacker model or mitigate them in the environment of our system in some other way.

\begin{enumerate}
\item \textbf{Corruption attack:} In \cite{mousa2017reputation} it was shown that DTSRS and thus also our reputation module can defend itself against corruption attack.
\item \textbf{On-off attack:} In \cite{mousa2017reputation} it was shown that DTSRS and thus also our reputation module can defend itself against on-off attack.
\item \textbf{Re-entry attack:} As Mousa et. al. states in \cite{mousa2015trust} "this attack was not considered by any of the current reputation based trust systems in participatory sensing" and thus no automated solution has been found in state-of-the-art reputation systems. If we want to protect our system against this type of fraud, we could add a manual function: the registration credential information would have to be checked manually either in general during registration  (for example, with proof of identity card) or during registration of a user's license plate (in cooperation with the authorities). This ensures that people can only register with their real identity and thus only once.
\item \textbf{Collusion attack:} In \cite{mousa2017reputation} it was shown that DTSRS and thus also our reputation module can defend itself against collusion attack.
\item \textbf{Sybil attack:} For the sybil attack the same applies as for the re-entry attack.
\item \textbf{Reputation lag exploitation:} In our system there is a time interval between the individual events of a user which cannot be influenced by the user himself. For malicous behavior as inspector, the user must first be selected as such. If parking spaces are blocked, the system is only informed when the user is reported, etc. It is not possible for a user to launch a large number of attacks in a very short time. Thus, the results of a fraud are already accounted for in the reputation score of the user when the next fraud case is evaluated.
\item \textbf{GPS spoofing attacks:} We do not use gps functions when receiving data because we already know the position of an event. If an inspector checks a fraud case, it is a parking space that is not available. The system already knows the position of this parking space. If an inspector does not travel to the location of the incident and simply guesses a result of his verification, it is called a corruption attack.
\item \textbf{Unfair ratings:} In the step "feedback processing" in \cite{mousa2017reputation} methods were implemented to mitigate the effect of an unfair rating attack.
\item \textbf{Bath mouthing or negative discrimination attack:} "Bad mouthing [...] attacks are not addressed by any of existing trust systems in participatory sensing" is explained in \cite{mousa2015trust}. However, the effect of this attack is also mitigated in our system. In contrast to DTSRS and Participatory Sensing, not every user can constantly give feedback in our system. To rate another user, you must first book or rent a parking space. While renting out one cannot freely choose the target of his bad mouthing attack. While renting one has to pay the parking price for every single rating he'd like to issue. In addition, the ratings of each individual user are publicly available and other users can easily recognize if the attacker discriminates against individual users. In addition, users who are unfairly rated badly will also return a bad rating in most cases.
\item \textbf{Ballot stuffing or positive discrimination attack:} Ballot stuffing is similar to bad mouthing. Even if two users always rate each other highly, fees must be paid to the operator for each related rental transaction.
\end{enumerate}

Because the reputation module can correctly distinguish between malicious and genuine users and it is used to check each report, we can decide whether the reporting or the reported user is the scammer. The trust of a contribution used for this is actually better than simply comparing the trust scores of the conflicting users, since in addition to the trust score, the contributions of the other users for this event and the proximity factor are also included there. \\

As shown, the module recognizes the scammers of class 1 cases (reported user is a scammer) and recognizes and protects itself against class 2 cases. The exceptional cases of class 3 are briefly discussed below: 


\subsection{Fraud Punishment}
The ability of fraud punishment is based on the ability of fraud detection. If a scammer is correctly identified, the system is able to penalize him. By registering, users have agreed to the rules of the system and can therefore be fined if they violate those rules. In the simplest case, the system receives the money by deducting it from the offender's credit balance and adding it to the system's credit balance. It is therefore obvious that the system receives the entire penalty and can use it for other purposes. If the scammer's credit balance becomes negative through deduction and is not recharged within a certain period of time, the operator receives the penalty in the form of an invoice for contractual penalty to the user.

\subsection{Fraud Prevention}
The system achieves fraud prevention through two methods. On the one hand, scammers are deterred and on the other hand, fraud is uncovered and scammers are thus eliminated.

Scammers are deterred by the public rating system and the well-known possibility of reporting. Anyone who intends to cheat considers twice whether they want to accept the resulting disadvantages, such as a poor rating or exclusion from the system. In addition, there is the fine you have to pay if you are discovered to be a scammer. Since these fines are invariably higher than the cost of using the system properly, fraud is not profitable.

As explained in the paragraph 'Fraud Dedection', scammers are discovered at the latest in the long run. On one hand, all other users notice from the scammer's rating that there is something wrong. The scammer is thus eliminated by the fact that nobody wants to book a parking space of his any more and he will no longer be able to book a parking space from users with manual confirmation, because most users only conclude contracts with users from whom they assume that everything will go as planned, i.e. users with a good rating. On the other hand, scammers are eliminated because they are excluded by the system. Anyone who has been discovered too often as a scammer or whose reputation score falls below a certain threshold will be banned.

\subsection{Fraud Compensation}
Also, fraud compensation can easily be performed once the system has the ability of correctly identifying the fraudster. Further up we have shown that the system has this ability. Once the fraudster has been clearly identified, it is also clear that the other party to the conflict is the injured party which must be compensated. \\

But even before this is clear, the reporting user was provided with a new parking space if required. The costs are initially borne by the system. However, once fraudsters and injured parties have been assigned, the system will recover these costs, as shown in the'Fraud Punishment' section. This means that there are no costs for the system if the scammer can be clearly identified. So if the reporting user was really the injured party, he got a replacement parking space without paying anything for it; he was compensated. If the reporting user was the scammer, however, he had to pay a fine afterwards, meaning that he paid for his replacement parking space by himself.


\section{Implementation}
The system is implemented according to the client-server model. Users utilize a smart phone as a client, while the operator provides a server on which a central database is hosted. Also running on the server is a web service that can be requested by the clients via a REST API. The web sercive forwards the request to the database system and also returns the response back to the clients. An Android app was developed for the clients using Java. The web service is also written in Java and runs on a Tomcat server, while a MySQL server has been set up for the database system.

\section{Future Work}

\section{Conclusion}

\section{Acknowledgments}
I would like to thank Prof. Dr. Alexandra Dmitrienko and the city of WÃ¼rzburg, who both supported me in creating this work.















%%%
%%% end main document
%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \appendix  %% include it, if something (bibliography, index, ...) follows below

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% bibliography
%%%
%%% available styles: abbrv, acm, alpha, apalike, ieeetr, plain, siam, unsrt
%%%
\bibliographystyle{plain}

%%% name of the bibliography file without .bib
%%% e.g.: literatur.bib -> \bibliography{literatur}
\bibliography{thesis}
%\printbibliography[heading=head]

\end{document}
%%% }}}
%%% END OF FILE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Notice!
%%% This file uses the outline-mode of emacs and the foldmethod of Vim.
%%% Press 'zi' to unfold the file in Vim.
%%% See ':help folding' for more information.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Local Variables:
%% mode: outline-minor
%% OPToutline-regexp: "%% .*"
%% OPTeval: (hide-body)
%% emerge-set-combine-versions-template: "%a\n%b\n"
%% End:
%% vim:foldmethod=marker
